{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "240d55eb-840c-4c9d-b0b3-ce9755d28c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in c:\\users\\hwayo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (6.0.12)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\hwayo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from feedparser) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac26a0ee-7436-4eb5-a9f2-269247a8ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 환경 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# === 환경설정 & 공통 상수 ===\n",
    "import requests, time, re, json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# 네이버가 빈 페이지/리다이렉트 주는 걸 막기 위한 헤더\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0\",\n",
    "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en;q=0.8\",\n",
    "    \"Referer\": \"https://www.naver.com/\"\n",
    "}\n",
    "\n",
    "# 프로젝트 경로(노트북 기준)\n",
    "RAW = Path(\"../data/raw\")\n",
    "PROC = Path(\"../data/processed\")\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✅ 환경 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78247e39-8c36-441a-a6f1-2ba6657e792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 유틸 로드\n"
     ]
    }
   ],
   "source": [
    "# === 기사 URL 패턴 & 유틸 ===\n",
    "ARTICLE_PATTERNS = [\n",
    "    re.compile(r\"https?://n\\.news\\.naver\\.com/article/\\d+/\\d+\"),\n",
    "    re.compile(r\"https?://n\\.news\\.naver\\.com/mnews/article/\\d+/\\d+\"),\n",
    "    re.compile(r\"https?://news\\.naver\\.com/main/read\\.naver.*[?&]oid=\\d+.*[?&]aid=\\d+\"),\n",
    "    re.compile(r\"https?://mnews\\.naver\\.com/article/\\d+/\\d+\"),\n",
    "]\n",
    "\n",
    "def is_article_url(href: str) -> bool:\n",
    "    if not href:\n",
    "        return False\n",
    "    return any(p.search(href) for p in ARTICLE_PATTERNS)\n",
    "\n",
    "def extract_oid_aid(url: str):\n",
    "    # n.news (PC/모바일)\n",
    "    m1 = re.search(r\"n\\.news\\.naver\\.com/(?:mnews/)?article/(\\d+)/(\\d+)\", url)\n",
    "    if m1:\n",
    "        return m1.group(1), m1.group(2)\n",
    "    # news.naver.com read.naver\n",
    "    m2_oid = re.search(r\"[?&]oid=(\\d+)\", url)\n",
    "    m2_aid = re.search(r\"[?&]aid=(\\d+)\", url)\n",
    "    if m2_oid and m2_aid:\n",
    "        return m2_oid.group(1), m2_aid.group(1)\n",
    "    return None, None\n",
    "\n",
    "def resolve_article_title(url, timeout=10):\n",
    "    \"\"\"기사 페이지에 직접 접속해 제목(og:title 우선)을 가져온다.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=timeout, allow_redirects=True)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        og = soup.select_one('meta[property=\"og:title\"]')\n",
    "        if og and og.get(\"content\"):\n",
    "            return og[\"content\"].strip()\n",
    "        if soup.title and soup.title.string:\n",
    "            return soup.title.string.strip()\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "print(\"✅ 유틸 로드\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92edb714-7f56-49ae-bfca-76d78419a828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 링크 수집 함수 준비\n"
     ]
    }
   ],
   "source": [
    "# === 뉴스 링크 수집 (검색 결과 HTML → 기사 URL) ===\n",
    "def get_news_links_html(query, pages=15, sleep_sec=0.25, issue_keywords=None):\n",
    "    \"\"\"\n",
    "    네이버 통합 뉴스검색에서 기사 링크/제목(임시)을 수집한다.\n",
    "    - query: '롬앤' 같이 넓게 넣을 것 (필요 시 '논란', '알레르기' 등은 후단 필터로 처리)\n",
    "    - issue_keywords: ['구순염','알레르기', ...]  # 제목 필터 (None이면 필터 끔)\n",
    "    \"\"\"\n",
    "    base = \"https://search.naver.com/search.naver\"\n",
    "    rows = []\n",
    "\n",
    "    for start_idx in range(1, pages*10, 10):  # 1, 11, 21, ...\n",
    "        params = {\"where\": \"news\", \"query\": query, \"start\": start_idx}\n",
    "        res = requests.get(base, headers=HEADERS, params=params, timeout=10)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # 대표 선택자 → 없으면 전체 a[href]에서 기사 패턴만\n",
    "        anchors = soup.select(\"a.title_link\")\n",
    "        if not anchors:\n",
    "            anchors = soup.select(\"a.news_tit\")\n",
    "        if not anchors:\n",
    "            anchors = [a for a in soup.find_all(\"a\", href=True)]\n",
    "\n",
    "        kept = 0\n",
    "        for a in anchors:\n",
    "            href = a.get(\"href\", \"\")\n",
    "            if not is_article_url(href):\n",
    "                continue\n",
    "            title = a.get_text(strip=True) or \"네이버뉴스\"\n",
    "\n",
    "            # (선택) 제목 키워드 필터\n",
    "            if issue_keywords:\n",
    "                t = title.lower()\n",
    "                if not any(k.lower() in t for k in issue_keywords):\n",
    "                    continue\n",
    "\n",
    "            rows.append({\"title\": title, \"url\": href, \"query\": query})\n",
    "            kept += 1\n",
    "\n",
    "        print(f\"page {start_idx}: kept {kept}\")\n",
    "        if kept == 0 and start_idx == 1:\n",
    "            break  # 첫 페이지부터 0이면 중단\n",
    "\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"url\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "print(\"✅ 링크 수집 함수 준비\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "253835d9-d751-4a13-965d-5164350c81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파라미터: romand 롬앤 구순염 None\n"
     ]
    }
   ],
   "source": [
    "# === 실행 파라미터 (브랜드별로 바꿔 쓰기) ===\n",
    "brand_code = \"romand\"  # 저장 파일명 등에 사용\n",
    "brand_query = \"롬앤 구순염\"   # 검색 쿼리(넓게)\n",
    "issue_keywords = None  # 우선 None으로 넓게 수집 후 다음 셀에서 제목 필터\n",
    "\n",
    "\n",
    "queries = [\"롬앤\", \"롬앤 틴트\", \"롬앤 논란\", \"롬앤 입술\", \"롬앤 알레르기\"]\n",
    "\n",
    "print(\"✅ 파라미터:\", brand_code, brand_query, issue_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c36727b9-8ae2-491a-bbeb-dece364f20a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1: kept 3\n",
      "page 11: kept 0\n",
      "page 21: kept 0\n",
      "page 31: kept 0\n",
      "page 41: kept 0\n",
      "page 51: kept 0\n",
      "page 61: kept 0\n",
      "page 71: kept 0\n",
      "page 81: kept 0\n",
      "page 91: kept 0\n",
      "page 101: kept 0\n",
      "page 111: kept 0\n",
      "page 121: kept 0\n",
      "page 131: kept 0\n",
      "page 141: kept 0\n",
      "수집 기사 수: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>네이버뉴스</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/009/000...</td>\n",
       "      <td>롬앤 구순염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버뉴스</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>롬앤 구순염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>네이버뉴스</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/018/000...</td>\n",
       "      <td>롬앤 구순염</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title                                                url   query\n",
       "0  네이버뉴스  https://n.news.naver.com/mnews/article/009/000...  롬앤 구순염\n",
       "1  네이버뉴스  https://n.news.naver.com/mnews/article/003/001...  롬앤 구순염\n",
       "2  네이버뉴스  https://n.news.naver.com/mnews/article/018/000...  롬앤 구순염"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이슈 필터 후: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>query</th>\n",
       "      <th>title_resolved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>네이버뉴스</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>롬앤 구순염</td>\n",
       "      <td>K뷰티 인디브랜드 대표주자 '롬앤', 공식해명에도 '구순염 논란' 지속 왜?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버뉴스</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/018/000...</td>\n",
       "      <td>롬앤 구순염</td>\n",
       "      <td>구순염 유발하는 K립 틴트?…논란에 환불까지, 무슨 일</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title                                                url   query  \\\n",
       "0  네이버뉴스  https://n.news.naver.com/mnews/article/003/001...  롬앤 구순염   \n",
       "1  네이버뉴스  https://n.news.naver.com/mnews/article/018/000...  롬앤 구순염   \n",
       "\n",
       "                               title_resolved  \n",
       "0  K뷰티 인디브랜드 대표주자 '롬앤', 공식해명에도 '구순염 논란' 지속 왜?  \n",
       "1              구순염 유발하는 K립 틴트?…논란에 환불까지, 무슨 일  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) 링크 수집 (넓게)\n",
    "html_df = get_news_links_html(brand_query, pages=15, issue_keywords=issue_keywords)\n",
    "print(\"수집 기사 수:\", len(html_df))\n",
    "display(html_df.head(3))\n",
    "\n",
    "# 2) 기사 페이지에서 실제 제목(og:title) 해석\n",
    "if len(html_df):\n",
    "    html_df[\"title_resolved\"] = html_df[\"url\"].apply(resolve_article_title)\n",
    "    # 너무 빠른 요청 방지\n",
    "    time.sleep(0.3)\n",
    "\n",
    "# 3) 제목 기반 이슈 필터 (필요 시 조정)\n",
    "issue_kw = [\"구순염\",\"염증\",\"알레르기\",\"입술\",\"자극\",\"논란\",\"부작용\",\"사과\",\"보상\",\"기만\",\"해명\"]\n",
    "pat = \"|\".join(issue_kw)\n",
    "filtered = (html_df\n",
    "            .dropna(subset=[\"title_resolved\"])\n",
    "            .loc[html_df[\"title_resolved\"].str.contains(pat, case=False, na=False)]\n",
    "            .drop_duplicates(subset=[\"url\"])\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "print(\"이슈 필터 후:\", len(filtered))\n",
    "display(filtered.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92209ce2-a625-46c3-a7c3-e38bd5f0152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 댓글 API 수집 ===\n",
    "def get_naver_comments(oid, aid, max_pages=20, sleep_sec=0.2):\n",
    "    \"\"\"\n",
    "    기사 한 개의 댓글을 수집한다. (최대 max_pages, 페이지당 20개)\n",
    "    반환: 리스트[ {user, contents, regTime}, ... ]\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for page in range(1, max_pages + 1):\n",
    "        api = \"https://apis.naver.com/commentBox/cbox/web_naver_list_jsonp.json\"\n",
    "        params = {\n",
    "            \"ticket\": \"news\",\n",
    "            \"templateId\": \"default_news\",\n",
    "            \"pool\": \"cbox5\",\n",
    "            \"lang\": \"ko\",\n",
    "            \"country\": \"KR\",\n",
    "            \"objectId\": f\"news{oid},{aid}\",\n",
    "            \"pageSize\": 20,\n",
    "            \"pageType\": 1,\n",
    "            \"page\": page,\n",
    "            \"sort\": \"FAVORITE\"\n",
    "        }\n",
    "        try:\n",
    "            res = requests.get(api, headers=HEADERS, params=params, timeout=10)\n",
    "        except Exception as e:\n",
    "            print(f\"  comments req err: {e}\")\n",
    "            break\n",
    "\n",
    "        txt = res.text.strip()\n",
    "        m = re.search(r\"\\((\\{.*\\})\\)$\", txt)  # JSONP → JSON\n",
    "        if not m:\n",
    "            break\n",
    "        data = json.loads(m.group(1))\n",
    "        lst = data.get(\"result\", {}).get(\"commentList\", [])\n",
    "        if not lst:\n",
    "            break\n",
    "\n",
    "        for c in lst:\n",
    "            out.append({\n",
    "                \"user\": c.get(\"userNameMasked\"),\n",
    "                \"contents\": c.get(\"contents\"),\n",
    "                \"regTime\": c.get(\"regTime\")\n",
    "            })\n",
    "        time.sleep(sleep_sec)\n",
    "    return out\n",
    "\n",
    "def collect_comments_for_links(df_links, brand_code, max_articles=15, max_comment_pages=10):\n",
    "    \"\"\"\n",
    "    링크 DF → oid/aid 추출 → 댓글 수집 → CSV 저장\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    target = df_links.head(max_articles)\n",
    "    for i, r in target.iterrows():\n",
    "        oid, aid = extract_oid_aid(r[\"url\"])\n",
    "        if not oid:\n",
    "            continue\n",
    "        print(f\"[{i+1}/{len(target)}] oid={oid}, aid={aid}\")\n",
    "        cmts = get_naver_comments(oid, aid, max_pages=max_comment_pages)\n",
    "        for c in cmts:\n",
    "            rows.append({\n",
    "                \"brand\": brand_code,\n",
    "                \"title\": r.get(\"title_resolved\") or r.get(\"title\"),\n",
    "                \"url\": r[\"url\"],\n",
    "                \"contents\": c[\"contents\"],\n",
    "                \"regTime\": c[\"regTime\"]\n",
    "            })\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    out_path = RAW / f\"comments_{brand_code}.csv\"\n",
    "    out.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"✅ 저장:\", out_path, \"rows:\", len(out))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f245b66-e4e8-4725-86f4-18a31d6394e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] oid=003, aid=0013514354\n",
      "[2/2] oid=018, aid=0006130833\n"
     ]
    }
   ],
   "source": [
    "# 댓글 대상 링크 선택: 필터 결과가 있으면 그걸, 없으면 원본 중 상위 N개\n",
    "links_for_comments = filtered if len(filtered) else html_df\n",
    "\n",
    "if len(links_for_comments) == 0:\n",
    "    print(\"❗ 기사 링크가 없습니다. query/필터를 완화하거나 pages를 늘려 다시 시도하세요.\")\n",
    "else:\n",
    "    comments_df = collect_comments_for_links(links_for_comments, brand_code,\n",
    "                                             max_articles=10, max_comment_pages=10)\n",
    "    display(comments_df.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
